{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from shapely.wkt import loads as load_wkt\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import openmeteo_requests\n",
    "import requests_cache\n",
    "from retry_requests import retry\n",
    "from "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "zipcodes = pd.read_csv(\"../data/ZIPCODES.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_weather_fact(zipcodes, start_date=\"2023-12-01 00:00:00\", end_date=\"2023-12-31 23:00:00\"):\n",
    "    \"\"\"\n",
    "    Generate a weather fact DataFrame for given ZIP codes within a specified date range.\n",
    "\n",
    "    Args:\n",
    "        zipcodes (DataFrame): A DataFrame containing ZIP codes and their geometries.\n",
    "        start_date (str): The start date for the weather data retrieval in \"YYYY-MM-DD HH:MM:SS\" format.\n",
    "        end_date (str): The end date for the weather data retrieval in \"YYYY-MM-DD HH:MM:SS\" format.\n",
    "\n",
    "    Returns:\n",
    "        DataFrame: A DataFrame containing weather facts for the specified ZIP codes and date range.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Convert 'the_geom' to geometry and calculate centroids\n",
    "    zipcodes['geometry'] = zipcodes['the_geom'].apply(load_wkt) \n",
    "    gdf = gpd.GeoDataFrame(zipcodes, geometry='geometry')\n",
    "    gdf['centroid'] = gdf['geometry'].centroid\n",
    "\n",
    "    gdf['centroid_latitude'] = gdf['centroid'].y\n",
    "    gdf['centroid_longitude'] = gdf['centroid'].x\n",
    "\n",
    "    # Extract unique locations\n",
    "    unique_locations = gdf[['ZIPCODE','centroid_latitude', 'centroid_longitude']].drop_duplicates()\n",
    "\n",
    "    # Setup the Open-Meteo API client with cache and retry on error\n",
    "    cache_session = requests_cache.CachedSession('.cache', expire_after=-1)\n",
    "    retry_session = retry(cache_session, retries=5, backoff_factor=0.2)\n",
    "    openmeteo = openmeteo_requests.Client(session=retry_session)\n",
    "\n",
    "    url = \"https://archive-api.open-meteo.com/v1/archive\"\n",
    "\n",
    "    # List to store all dataframes\n",
    "    dfs = []\n",
    "\n",
    "    # Iterate over DataFrame rows\n",
    "    for _, row in unique_locations.iterrows():\n",
    "        params = {\n",
    "            \"latitude\": row['centroid_latitude'],\n",
    "            \"longitude\": row['centroid_longitude'],\n",
    "            \"start_date\": start_date,\n",
    "            \"end_date\": end_date,\n",
    "            \"hourly\": [\n",
    "                \"temperature_2m\", \"relative_humidity_2m\", \"precipitation\", \"rain\", \n",
    "                \"snowfall\", \"windspeed_10m\", \"winddirection_10m\"\n",
    "            ],\n",
    "            \"timezone\": \"auto\"\n",
    "        }\n",
    "        \n",
    "        try:\n",
    "            responses = openmeteo.weather_api(url, params=params)\n",
    "            # Process first location\n",
    "            response = responses[0]\n",
    "\n",
    "            # Use indices based on the API documentation\n",
    "            hourly = response.Hourly()\n",
    "            hourly_temperature_2m = hourly.Variables(0).ValuesAsNumpy()\n",
    "            hourly_relative_humidity_2m = hourly.Variables(1).ValuesAsNumpy()\n",
    "            hourly_precipitation = hourly.Variables(2).ValuesAsNumpy()\n",
    "            hourly_rain = hourly.Variables(3).ValuesAsNumpy()\n",
    "            hourly_snowfall = hourly.Variables(4).ValuesAsNumpy()\n",
    "            hourly_windspeed_10m = hourly.Variables(5).ValuesAsNumpy()\n",
    "            hourly_winddirection_10m = hourly.Variables(6).ValuesAsNumpy()\n",
    "\n",
    "            hourly_data = {\n",
    "                \"date\": pd.date_range(\n",
    "                    start=pd.to_datetime(hourly.Time(), unit=\"s\", utc=True),\n",
    "                    end=pd.to_datetime(hourly.TimeEnd(), unit=\"s\", utc=True),\n",
    "                    freq=pd.Timedelta(seconds=hourly.Interval()),\n",
    "                    inclusive=\"left\"\n",
    "                ),\n",
    "                \"temperature_2m\": hourly_temperature_2m,\n",
    "                \"relative_humidity_2m\": hourly_relative_humidity_2m,\n",
    "                \"precipitation\": hourly_precipitation,\n",
    "                \"rain\": hourly_rain,\n",
    "                \"snowfall\": hourly_snowfall,\n",
    "                \"windspeed_10m\": hourly_windspeed_10m,\n",
    "                \"winddirection_10m\": hourly_winddirection_10m\n",
    "            }\n",
    "\n",
    "            hourly_dataframe = pd.DataFrame(data=hourly_data)\n",
    "            hourly_dataframe['ZIPCODE'] = row['ZIPCODE']  # Add ZIP code to the dataframe\n",
    "            hourly_dataframe['Latitude'] = row['centroid_latitude']  # Add Latitude to the dataframe\n",
    "            hourly_dataframe['Longitude'] = row['centroid_longitude']  # Add Longitude to the dataframe\n",
    "\n",
    "            dfs.append(hourly_dataframe)\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(\"An error occurred:\", e)\n",
    "            print(\"Response content:\", responses)\n",
    "\n",
    "    # Concatenate all dataframes\n",
    "    result = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "    # Generate unique keys\n",
    "    result['LocationAreaKey'] = (\n",
    "        result['Longitude'].astype(str).str.replace('.', '', regex=False).str.replace('-', '', regex=False).str[:8] +\n",
    "        result['Latitude'].astype(str).str.replace('.', '', regex=False).str.replace('-', '', regex=False).str[:8]\n",
    "    )\n",
    "\n",
    "    result['DateHourKey'] = result['date'].dt.strftime('%Y%m%d%H')\n",
    "    \n",
    "    result['WeatherKey'] = (\n",
    "        result['DateHourKey'].astype(str)[2:] + \n",
    "        result['Longitude'].astype(str).str.replace('.', '', regex=False).str.replace('-', '', regex=False).str[1:6] +\n",
    "        result['Latitude'].astype(str).str.replace('.', '', regex=False).str.replace('-', '', regex=False).str[1:6]\n",
    "    )\n",
    "    result['WeatherKey'] = (result['LocationAreaKey'].astype(str) + '_' + result['date'].astype(str)).apply(hash).apply(abs)\n",
    "\n",
    "    # Prepare the WeatherFact DataFrame\n",
    "    WeatherFact = result.drop(columns=['date', 'Latitude', 'Longitude', 'ZIPCODE'])\n",
    "    WeatherFact = WeatherFact.rename(columns={\n",
    "        \"temperature_2m\": \"Temperature\",\n",
    "        \"relative_humidity_2m\": \"Humidity\",\n",
    "        \"precipitation\": \"Precipitation\",\n",
    "        \"rain\": \"Rain\",\n",
    "        \"snowfall\": \"Snow\",\n",
    "        \"windspeed_10m\": \"WindSpeed\",\n",
    "        \"winddirection_10m\": \"WindDirection\"\n",
    "    })\n",
    "\n",
    "    return WeatherFact\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'15010102'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'2015010102'[2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "849720"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(WeatherFact)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WeatherKey\n",
       "1844956414405353242    1\n",
       "24186297389293135      1\n",
       "7624193843777569506    1\n",
       "2064409689231402522    1\n",
       "6903805245174190757    1\n",
       "                      ..\n",
       "4853977413593574427    1\n",
       "915303560342164488     1\n",
       "1113894982518626950    1\n",
       "7140382137451059871    1\n",
       "2420000414799937287    1\n",
       "Name: count, Length: 849720, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "WeatherFact['WeatherKey'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "WeatherFact = generate_weather_fact(zipcodes, start_date=\"2023-01-01\", end_date=\"2023-12-31\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "97"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "WeatherFact['LocationAreaKey'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "WeatherFact.to_csv('../data/dwh/WeatherFact.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
